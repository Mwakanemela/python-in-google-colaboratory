{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPULepKmFHT2EKUIEykMCju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mwakanemela/python-in-google-colaboratory/blob/main/NLP_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DrU8rgDq4J-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy\n",
        "# !python install -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_md\n",
        "# !python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "RM7hj5Fy4NV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag-of-words"
      ],
      "metadata": {
        "id": "1B5_90Ny3Ewl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model to train on**"
      ],
      "metadata": {
        "id": "qCJU642ziR8f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a63kfCKhY4H8"
      },
      "outputs": [],
      "source": [
        "class category:\n",
        "  BOOKS = \"BOOKS\"\n",
        "  CLOTHING = \"CLOTHING\"\n",
        "\n",
        "train_x = [\"i love the book\", \"this is a great book\", \"the fit is great\", \"i love the shoes\"]\n",
        "train_y = [category.BOOKS, category.BOOKS, category.CLOTHING, category.CLOTHING]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "train_x_vector = vectorizer.fit_transform(train_x)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "# print(vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUVUo2yliQYu",
        "outputId": "cc906512-a496-46d4-f27d-42744732f4b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['book' 'fit' 'great' 'is' 'love' 'shoes' 'the' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf_svm = svm.SVC(kernel='linear')\n",
        "clf_svm.fit(train_x_vector, train_y)\n",
        "\n",
        "text_to_transform = input(\"Enter text to predict(transform): \")\n",
        "test_x = vectorizer.transform([text_to_transform])\n",
        "clf_svm.predict(test_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRUsIHi8i52N",
        "outputId": "8d328064-b542-4119-edaa-a279adba2f61",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter text to predict(transform): reading the books\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CLOTHING'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word vectors"
      ],
      "metadata": {
        "id": "uLpIlRps3a2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "JrVd5gIs3ewb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x)"
      ],
      "metadata": {
        "id": "kBMf0VvYAxyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6711ca-7152-49d6-a77f-8a5e8ae542d0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i love the book', 'this is a great book', 'the fit is great', 'i love the shoes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "docs = [nlp(text) for text in train_x]\n",
        "train_x_word_vector = [x.vector for x in docs]\n",
        "\n",
        "\n",
        "clf_svm_wv = svm.SVC(kernel='linear')\n",
        "clf_svm_wv.fit(train_x_word_vector, train_y)\n",
        "\n",
        "text_to_transform = input(\"Enter text to predict(transform): \")\n",
        "test_x = [text_to_transform]\n",
        "test_docs = [nlp(text) for text in test_x]\n",
        "test_x_docs = [x.vector for x in test_docs]\n",
        "clf_svm_wv.predict(test_x_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_E8atGXhlFB",
        "outputId": "2c3ae402-0ec9-4202-a20b-6989de01319e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter text to predict(transform): reading the books\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BOOKS'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6yHysfgih_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular Expressions (Regex)\n"
      ],
      "metadata": {
        "id": "2jcR_AJdss6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex = re.compile(r\"^ab.*\\Scd$\") #all words that start with ab and end with cd with inbetween words no space allowed\n",
        "phrases = [\"abcd\", \"ab cd\", \"abmwakacd\", \"people\", \"abccd\"]\n",
        "matches = []\n",
        "\n",
        "for phrase in phrases:\n",
        "  if re.match(regex, phrase):\n",
        "    matches.append(phrase)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrcgnQnGsyJE",
        "outputId": "e4b3fe45-db64-4cd7-bee9-4febfe857fcd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abmwakacd', 'abccd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "regex = re.compile(r\"read|story|\\bbook\\b\")\n",
        "phrases = [\"I like  books\", \"I read a history\", \"I read a history\", \"This book characters\", \"for the peole\", \"to the people\"]\n",
        "matches = []\n",
        "\n",
        "for phrase in phrases:\n",
        "  if re.search(regex, phrase):\n",
        "    matches.append(phrase)\n",
        "print(matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssiHwSTotspU",
        "outputId": "e1537bbb-4cca-4725-e8cb-1456edc8415e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I read a history', 'I read a history', 'This book characters']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nhre-NKvu5Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming/Lemmatization in Python (text normalization w/ NLTK library)\n",
        "\n"
      ],
      "metadata": {
        "id": "PYF-EmDXyMZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5n6XlkPayTIZ",
        "outputId": "7b9ddb47-a382-49d6-da99-b12cd9c89082"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "phrase = input(\"Enter a phrase to stem: \")\n",
        "words = word_tokenize(phrase)\n",
        "\n",
        "stemmed_words = []\n",
        "\n",
        "for word in words:\n",
        "  stemmed_words.append(stemmer.stem(word))\n",
        "\n",
        "\" \".join(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8rFBpuh2yeRi",
        "outputId": "2baf1d57-ecc9-425d-bbe0-c3c268f448cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a phrase to stem: reading the books\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read the book'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmanatizer = WordNetLemmatizer()\n",
        "phrase = input(\"Enter a phrase to stem: \")\n",
        "words = word_tokenize(phrase)\n",
        "\n",
        "lemmetized_words = []\n",
        "\n",
        "for word in words:\n",
        "  lemmetized_words.append(lemmanatizer.lemmatize(word))\n",
        "\n",
        "\" \".join(lemmetized_words)"
      ],
      "metadata": {
        "id": "swEoaztLzd4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e9d942d9-7a86-430d-efdb-8301167bcdac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a phrase to stem: reading the books\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reading the book'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrPfN_YySH0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}